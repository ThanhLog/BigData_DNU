import pandas as pd
import matplotlib
# C·∫•u h√¨nh matplotlib ƒë·ªÉ s·ª≠ d·ª•ng backend kh√¥ng c·∫ßn Tcl/Tk
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import r2_score, mean_squared_error

# ƒê∆∞·ªùng d·∫´n ƒë√∫ng v·ªõi c√°c forward slashes ho·∫∑c escaped backslashes
try:
    # Ki·ªÉm tra c√°c file Spark ƒë√£ t·∫°o - Spark l∆∞u th√†nh nhi·ªÅu ph·∫ßn
    import glob
    import os
    
    lr_path = "D:/Big_data/predictions_lr.csv"
    rf_path = "D:/Big_data/predictions_rf.csv"
    cv_path = "D:/Big_data/predictions_cv.csv"
    
    # T√¨m t·∫•t c·∫£ c√°c file CSV trong th∆∞ m·ª•c
    lr_files = glob.glob(os.path.join(lr_path, "*.csv"))
    rf_files = glob.glob(os.path.join(rf_path, "*.csv"))
    cv_files = glob.glob(os.path.join(cv_path, "*.csv"))
    
    # ƒê·ªçc v√† gh√©p c√°c file
    lr_predictions = None
    rf_predictions = None
    cv_predictions = None
    
    # Ki·ªÉm tra c√≥ file hay kh√¥ng tr∆∞·ªõc khi ƒë·ªçc
    if lr_files:
        lr_dfs = [pd.read_csv(file) for file in lr_files if os.path.getsize(file) > 0]
        if lr_dfs:
            lr_predictions = pd.concat(lr_dfs, ignore_index=True)
    
    if rf_files:
        rf_dfs = [pd.read_csv(file) for file in rf_files if os.path.getsize(file) > 0]
        if rf_dfs:
            rf_predictions = pd.concat(rf_dfs, ignore_index=True)
    
    if cv_files:
        cv_dfs = [pd.read_csv(file) for file in cv_files if os.path.getsize(file) > 0]
        if cv_dfs:
            cv_predictions = pd.concat(cv_dfs, ignore_index=True)
    
    # N·∫øu kh√¥ng t√¨m th·∫•y c√°c file con, th·ª≠ ƒë·ªçc tr·ª±c ti·∫øp (n·∫øu Spark ƒë√£ g·ªôp th√†nh m·ªôt file)
    if lr_predictions is None and os.path.exists(lr_path):
        try:
            lr_predictions = pd.read_csv(lr_path)
        except:
            pass
    
    if rf_predictions is None and os.path.exists(rf_path):
        try:
            rf_predictions = pd.read_csv(rf_path)
        except:
            pass
            
    if cv_predictions is None and os.path.exists(cv_path):
        try:
            cv_predictions = pd.read_csv(cv_path)
        except:
            pass
    
    # Th·ª≠ c√°ch kh√°c - ƒë·ªçc tr·ª±c ti·∫øp c√°c file ph·∫ßn 
    if lr_predictions is None:
        direct_lr = "D:/Big_data/predictions_lr.csv/part-00000-*.csv"
        direct_lr_files = glob.glob(direct_lr)
        if direct_lr_files:
            lr_predictions = pd.read_csv(direct_lr_files[0])
    
    if rf_predictions is None:
        direct_rf = "D:/Big_data/predictions_rf.csv/part-00000-*.csv"
        direct_rf_files = glob.glob(direct_rf)
        if direct_rf_files:
            rf_predictions = pd.read_csv(direct_rf_files[0])
    
    if cv_predictions is None:
        direct_cv = "D:/Big_data/predictions_cv.csv/part-00000-*.csv"
        direct_cv_files = glob.glob(direct_cv)
        if direct_cv_files:
            cv_predictions = pd.read_csv(direct_cv_files[0])
    
    # Ki·ªÉm tra xem ƒë√£ ƒë·ªçc ƒë∆∞·ª£c d·ªØ li·ªáu ch∆∞a
    if lr_predictions is None or rf_predictions is None or cv_predictions is None:
        print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc m·ªôt ho·∫∑c nhi·ªÅu file d·ª± ƒëo√°n. H√£y ki·ªÉm tra ƒë∆∞·ªùng d·∫´n v√† c·∫•u tr√∫c th∆∞ m·ª•c.")
        
        # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ c√°c file t√¨m th·∫•y
        print("\nTh√¥ng tin debug:")
        print(f"lr_files: {lr_files}")
        print(f"rf_files: {rf_files}")
        print(f"cv_files: {cv_files}")
        
        # T√¨m ki·∫øm t·∫•t c·∫£ c√°c file c√≥ th·ªÉ li√™n quan trong th∆∞ m·ª•c
        all_csv = glob.glob("D:/Big_data/**/*.csv", recursive=True)
        print(f"\nT·∫•t c·∫£ c√°c file CSV t√¨m th·∫•y trong D:/Big_data/:")
        for csv_file in all_csv:
            print(f"  - {csv_file}")
            
        # K·∫øt th√∫c
        import sys
        sys.exit(1)
        
    # ƒê·∫∑t t√™n cho m·ªói DataFrame ƒë·ªÉ d·ªÖ ph√¢n bi·ªát
    lr_predictions['model'] = 'Linear Regression'
    rf_predictions['model'] = 'Random Forest'
    cv_predictions['model'] = 'Cross Validation'
    
    # K·∫øt h·ª£p d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ c√°c m√¥ h√¨nh
    all_predictions = pd.concat([lr_predictions, rf_predictions, cv_predictions])
    
    # Thi·∫øt l·∫≠p style cho bi·ªÉu ƒë·ªì
    plt.rcParams['figure.figsize'] = (12, 8)
    plt.rcParams['font.size'] = 12
    
    # 1. So s√°nh gi√° tr·ªã th·ª±c t·∫ø v·ªõi d·ª± ƒëo√°n c·ªßa t·ª´ng m√¥ h√¨nh
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # D·ªØ li·ªáu cho m·ªói m√¥ h√¨nh
    models_data = {
        'Linear Regression': lr_predictions,
        'Random Forest': rf_predictions,
        'Cross Validation': cv_predictions
    }
    
    # V·∫Ω bi·ªÉu ƒë·ªì scatter cho t·ª´ng m√¥ h√¨nh
    for i, (model_name, data) in enumerate(models_data.items()):
        # L·ªçc d·ªØ li·ªáu ƒë·ªÉ kh√¥ng hi·ªÉn th·ªã qu√° nhi·ªÅu ƒëi·ªÉm
        sample = data.sample(n=min(500, len(data)))
        
        # T√≠nh R2 v√† RMSE
        r2 = r2_score(sample['Confirmed'], sample['prediction'])
        rmse = np.sqrt(mean_squared_error(sample['Confirmed'], sample['prediction']))
        
        # V·∫Ω bi·ªÉu ƒë·ªì
        axes[i].scatter(sample['Confirmed'], sample['prediction'], alpha=0.5)
        
        # V·∫Ω ƒë∆∞·ªùng xu h∆∞·ªõng (ƒë∆∞·ªùng th·∫≥ng l√Ω t∆∞·ªüng)
        max_val = max(sample['Confirmed'].max(), sample['prediction'].max())
        axes[i].plot([0, max_val], [0, max_val], 'r--')
        
        axes[i].set_title(f'{model_name}\nR¬≤ = {r2:.4f}, RMSE = {rmse:.4f}')
        axes[i].set_xlabel('Gi√° tr·ªã th·ª±c t·∫ø')
        axes[i].set_ylabel('Gi√° tr·ªã d·ª± ƒëo√°n')
        axes[i].grid(True)
    
    plt.tight_layout()
    plt.savefig('D:/Big_data/actual_vs_predicted.png', dpi=300)
    plt.close()
    
    # 2. Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi sai s·ªë cho t·ª´ng m√¥ h√¨nh
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    for i, (model_name, data) in enumerate(models_data.items()):
        # T√≠nh sai s·ªë
        data['error'] = data['prediction'] - data['Confirmed']
        
        # V·∫Ω bi·ªÉu ƒë·ªì ph√¢n ph·ªëi sai s·ªë (histogram thay v√¨ seaborn)
        axes[i].hist(data['error'], bins=30, alpha=0.7, density=True)
        
        # T√≠nh sai s·ªë trung b√¨nh
        mean_error = data['error'].mean()
        median_error = data['error'].median()
        
        axes[i].axvline(mean_error, color='r', linestyle='--', label=f'Trung b√¨nh: {mean_error:.2f}')
        axes[i].axvline(median_error, color='g', linestyle='--', label=f'Trung v·ªã: {median_error:.2f}')
        
        axes[i].set_title(f'Ph√¢n ph·ªëi sai s·ªë - {model_name}')
        axes[i].set_xlabel('Sai s·ªë (D·ª± ƒëo√°n - Th·ª±c t·∫ø)')
        axes[i].set_ylabel('M·∫≠t ƒë·ªô')
        axes[i].legend()
    
    plt.tight_layout()
    plt.savefig('D:/Big_data/error_distribution.png', dpi=300)
    plt.close()
    
    # 3. So s√°nh hi·ªáu su·∫•t c√°c m√¥ h√¨nh
    # T·∫°o DataFrame ƒë·ªÉ l∆∞u tr·ªØ c√°c metric ƒë√°nh gi√°
    metrics = []
    
    for model_name, data in models_data.items():
        r2 = r2_score(data['Confirmed'], data['prediction'])
        rmse = np.sqrt(mean_squared_error(data['Confirmed'], data['prediction']))
        
        metrics.append({
            'Model': model_name,
            'R2': r2,
            'RMSE': rmse
        })
    
    metrics_df = pd.DataFrame(metrics)
    
    # V·∫Ω bi·ªÉu ƒë·ªì c·ªôt so s√°nh R2
    fig, ax1 = plt.subplots(figsize=(12, 6))
    
    x = np.arange(len(metrics_df['Model']))
    width = 0.35
    
    # Tr·ª•c ch√≠nh cho R2
    bar1 = ax1.bar(x - width/2, metrics_df['R2'], width, label='R¬≤', color='skyblue')
    ax1.set_ylabel('R¬≤ (c√†ng cao c√†ng t·ªët)', color='blue')
    ax1.set_ylim(0, 1.05)
    
    # Tr·ª•c th·ª© hai cho RMSE
    ax2 = ax1.twinx()
    bar2 = ax2.bar(x + width/2, metrics_df['RMSE'], width, label='RMSE', color='lightcoral')
    ax2.set_ylabel('RMSE (c√†ng th·∫•p c√†ng t·ªët)', color='red')
    
    # Th√™m nh√£n v√† ti√™u ƒë·ªÅ
    ax1.set_xticks(x)
    ax1.set_xticklabels(metrics_df['Model'])
    ax1.set_title('So s√°nh hi·ªáu su·∫•t c√°c m√¥ h√¨nh')
    
    # Th√™m gi√° tr·ªã l√™n ƒë·∫ßu c·ªôt
    def add_labels(bars, ax):
        for bar in bars:
            height = bar.get_height()
            ax.annotate(f'{height:.4f}',
                        xy=(bar.get_x() + bar.get_width() / 2, height),
                        xytext=(0, 3),  # 3 points vertical offset
                        textcoords="offset points",
                        ha='center', va='bottom')
    
    add_labels(bar1, ax1)
    add_labels(bar2, ax2)
    
    # Th√™m ch√∫ th√≠ch
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
    
    plt.tight_layout()
    plt.savefig('D:/Big_data/model_comparison.png', dpi=300)
    plt.close()
    
    # T·∫°o th√™m m·ªôt b√°o c√°o v·ªÅ c√°c ch·ªâ s·ªë hi·ªáu su·∫•t
    with open('D:/Big_data/model_performance_report.txt', 'w', encoding="utf-8") as f:
        f.write("B√ÅO C√ÅO HI·ªÜU SU·∫§T M√î H√åNH\n")
        f.write("=" * 50 + "\n\n")
        
        for index, row in metrics_df.iterrows():
            f.write(f"M√¥ h√¨nh: {row['Model']}\n")
            f.write(f"R¬≤ Score: {row['R2']:.6f}\n")
            f.write(f"RMSE: {row['RMSE']:.6f}\n")
            f.write("-" * 50 + "\n\n")
        
        # X√°c ƒë·ªãnh m√¥ h√¨nh t·ªët nh·∫•t
        best_r2_model = metrics_df.loc[metrics_df['R2'].idxmax(), 'Model']
        best_rmse_model = metrics_df.loc[metrics_df['RMSE'].idxmin(), 'Model']
        
        f.write(f"M√¥ h√¨nh c√≥ R¬≤ cao nh·∫•t: {best_r2_model}\n")
        f.write(f"M√¥ h√¨nh c√≥ RMSE th·∫•p nh·∫•t: {best_rmse_model}\n")
        
    print("‚úÖ ƒê√£ t·∫°o c√°c bi·ªÉu ƒë·ªì v√† l∆∞u v√†o th∆∞ m·ª•c D:/Big_data/")
    print("üìä C√°c file bi·ªÉu ƒë·ªì:")
    print("  - actual_vs_predicted.png")
    print("  - error_distribution.png")
    print("  - model_comparison.png")
    print("  - model_performance_report.txt")

except Exception as e:
    print(f"‚ùå ƒê√£ x·∫£y ra l·ªói: {e}")
    import traceback
    traceback.print_exc()
    print("\nH√£y ƒë·∫£m b·∫£o:")
    print("1. ƒê√£ ch·∫°y m√£ ngu·ªìn d·ª± ƒëo√°n v√† t·∫°o c√°c file CSV")
    print("2. ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c file CSV ch√≠nh x√°c")
    print("3. T·∫•t c·∫£ c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t (pandas, matplotlib, numpy, sklearn)")